{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faec64f9-7525-4911-96b8-23a6846bc403",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Practice - Twitter classifier\n",
    "With the Tweet Corpus from two Twitter accounts (archives from Ariana Grande and Trump)\n",
    "\n",
    "2) \n",
    "3) Set up and fit a linear model and predict which account an input tweet is from and its probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03887a9-6f2a-41f4-9389-b13bb3544b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff326d4-30df-49ae-bb6c-379be4a47d6a",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "You may find these useful in the lab. Feel free to modify for your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b872392-ee78-41f3-b2d6-6cdf776a084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_examples(data, probs, label1, label2, n=10):\n",
    "    percent = lambda x: \"{}%\".format(round(x*100, 1))\n",
    "    \n",
    "    for text, pred in list(zip(data, probs))[:n]:\n",
    "        print(\"{}\\n{}: {} / {}: {}\\n{}\".format(\n",
    "            text,\n",
    "            label1,\n",
    "            percent(pred[0]),\n",
    "            label2,\n",
    "            percent(pred[1]),\n",
    "            \"-\"*50  # to print a line\n",
    "        ))\n",
    "        \n",
    "def predict(model, vectorizer, data, all_predictions=False):\n",
    "    data = vectorizer.transform(data)\n",
    "    if all_predictions:\n",
    "        return model.predict_proba(data)\n",
    "    else:\n",
    "        return model.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d44c2e7-c49d-4470-90a6-f5493fb19860",
   "metadata": {},
   "source": [
    "### Cleaning function\n",
    "Create a simple text cleaning function, as tweets are sensitive to major reformatting. You may experiment with this statement!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32521d28-e16a-415c-b50b-a8224d956f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_text_clean(text):\n",
    "    tokens =  TweetTokenizer().tokenize(str(text).lower())\n",
    "    stop = stopwords.words(\"english\")\n",
    "    return \" \".join([w for w in tokens if w.lower() not in stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0751a34-9e92-420e-8a8e-f60f2a2513b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fetch data from /twitter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa0d488-c24e-4bce-a500-96e5384a1679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets(name, test_size=0.1):\n",
    "    with open(\"twitter_data/{}.json\".format(name)) as f:\n",
    "        #raw_tweets = json.load(f)\n",
    "        tweets = [t.get(\"text\") for t in json.load(f)]\n",
    "        #tweets = list(map(lambda x: x.get(\"text\"), raw_tweets))\n",
    "        cleaned = [twitter_text_clean(t) for t in tweets]\n",
    "        #cleaned = list(map(twitter_text_clean, tweets))\n",
    "        \n",
    "        return train_test_split(cleaned, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a930c26-3f85-41eb-a0c0-bf3f68523dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: experiment with this parameter!\n",
    "\"\"\"\n",
    "initially gather a train and test set of each tweet file.\n",
    "below, we use train to create another test set to evaluate the model\n",
    "\n",
    "this means the two test datasets below \\\n",
    "are completely unseen to the model we train\n",
    "\"\"\"\n",
    "test_split = 0.2\n",
    "ariana_train, ariana_test = tweets(\"ariana\", test_size=test_split)\n",
    "trump_train, trump_test = tweets(\"trump\", test_size=test_split)\n",
    "\n",
    "y = [1]*len(ariana_train) + [0]*len(trump_train)\n",
    "x = ariana_train + trump_train\n",
    "print(\"Train samples: {}\".format(len(x)))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.1, random_state=4310)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531eaa5e-140c-4958-b14d-3b919a99266b",
   "metadata": {},
   "source": [
    "### TF-IDF + logistic regression\n",
    "- Vectorize the tweets (e.g. with Count Vectorizer or TF-IDF Vectorizer).\n",
    "- Logistic regression is neat because it spits out whether something is true or not.\n",
    "    - This is exactly what we want in this case, to determine between two types of tweet sources (1 or 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dec3930-b21b-43fb-adb4-bfa6d3e1fb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "# define regression and fit\n",
    "LR = LogisticRegression()\n",
    "LR.fit(vectorizer.fit_transform(X_train), y_train)\n",
    "\n",
    "# evaluate by confusion matrix\n",
    "y_pred = predict(LR, vectorizer, X_test)\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e5af6a-ba13-436b-8236-60880f15af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ariana_prob = predict(LR, vectorizer, ariana_test, all_predictions=True)\n",
    "print_examples(ariana_test, ariana_prob, \"Trump\", \"Ariana\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5064f616-39ac-432d-ba69-4dc8297397a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_prob = predict(LR, vectorizer, trump_test, all_predictions=True)\n",
    "print_examples(trump_test, trump_prob, \"Trump\", \"Ariana\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('base')",
   "language": "python",
   "name": "python399jvsc74a57bd029553384b1b01f6109f5069a08d409f2dc5adeb046ccd0e94d694cc3c1cd07a6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
